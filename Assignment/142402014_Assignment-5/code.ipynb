{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CIFAR-10 & CIFAR-100 SEQUENTIAL TRAINING USING W&B\n",
        "# ============================================================================\n",
        "import wandb\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------------------------\n",
        "# Patch WandB Graph to Avoid Keras Graph Bug\n",
        "# ----------------------------------------------------------------------------\n",
        "from wandb.sdk.data_types import graph\n",
        "def patched_from_keras(cls, model):\n",
        "    return None\n",
        "graph.Graph.from_keras = classmethod(patched_from_keras)\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------------------------\n",
        "# Function: Build Simple CNN (can replace with ViT if you want)\n",
        "# ----------------------------------------------------------------------------\n",
        "def build_cnn(num_classes):\n",
        "    model = keras.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(256, activation='relu'),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------------------------\n",
        "# Function: Train on a dataset (CIFAR-10 or CIFAR-100)\n",
        "# ----------------------------------------------------------------------------\n",
        "def train_on_dataset(dataset_name, num_classes, run_name, pretrained_model=None):\n",
        "    wandb.init(\n",
        "        project=\"Q4-cifar-transfer-learning\",\n",
        "        name=run_name,\n",
        "        config={\"dataset\": dataset_name, \"epochs\": 100, \"num_classes\": num_classes},\n",
        "        settings=wandb.Settings(_disable_stats=True)\n",
        "    )\n",
        "\n",
        "    # Load dataset\n",
        "    if dataset_name == \"cifar100\":\n",
        "        (x_train, y_train), (x_test, y_test) = keras.datasets.cifar100.load_data()\n",
        "    elif dataset_name == \"cifar10\":\n",
        "        (x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "    else:\n",
        "        raise ValueError(\"Dataset must be 'cifar10' or 'cifar100'.\")\n",
        "\n",
        "    x_train, x_test = x_train.astype(\"float32\") / 255.0, x_test.astype(\"float32\") / 255.0\n",
        "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "    # Model\n",
        "    if pretrained_model:\n",
        "        base = pretrained_model\n",
        "        base.pop()  # remove old head\n",
        "        base.add(layers.Dense(num_classes, activation='softmax'))  # new head\n",
        "        model = base\n",
        "        print(f\"Transferred model → now training on {dataset_name}\")\n",
        "    else:\n",
        "        model = build_cnn(num_classes)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
        "        loss=\"categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "    # Train\n",
        "    model.fit(\n",
        "        x_train, y_train,\n",
        "        validation_data=(x_test, y_test),\n",
        "        epochs=100,\n",
        "        batch_size=128,\n",
        "        callbacks=[wandb.keras.WandbCallback(save_model=False)]\n",
        "    )\n",
        "\n",
        "    wandb.finish()\n",
        "    return model\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "#  Sequential Experiments\n",
        "# ============================================================================\n",
        "\n",
        "# --- (a) CIFAR-100 → CIFAR-10 ---\n",
        "print(\"\\n=== Training CIFAR-100 → CIFAR-10 ===\")\n",
        "model_100 = train_on_dataset(\"cifar100\", 100, \"CIFAR100_first\")\n",
        "train_on_dataset(\"cifar10\", 10, \"CIFAR10_after_CIFAR100\", pretrained_model=model_100)\n",
        "\n",
        "# --- (b) CIFAR-10 → CIFAR-100 ---\n",
        "print(\"\\n=== Training CIFAR-10 → CIFAR-100 ===\")\n",
        "model_10 = train_on_dataset(\"cifar10\", 10, \"CIFAR10_first\")\n",
        "train_on_dataset(\"cifar100\", 100, \"CIFAR100_after_CIFAR10\", pretrained_model=model_10)\n"
      ],
      "metadata": {
        "id": "RaMVMFP-WK5c"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Assignment 5: Weak Supervision NER (Final Working Version)\n",
        "# ============================================\n",
        "\n",
        "# Install dependencies if needed\n",
        "# !pip install datasets snorkel wandb pandas\n",
        "\n",
        "import datasets\n",
        "import wandb\n",
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from snorkel.labeling import labeling_function, LFApplier, LFAnalysis\n",
        "from snorkel.labeling.model.baselines import MajorityLabelVoter\n",
        "\n",
        "# ===============================\n",
        "# Step 1: Initialize W&B and Load Dataset\n",
        "# ===============================\n",
        "wandb.init(project=\"Q1-weak-supervision-ner\")\n",
        "\n",
        "# Load CoNLL-2003 dataset (Parquet format)\n",
        "dataset = datasets.load_dataset(\"eriktks/conll2003\", revision=\"convert/parquet\")\n",
        "\n",
        "# Flatten dataset to token-level DataFrame\n",
        "rows = []\n",
        "for doc in dataset['train']:\n",
        "    for token, label in zip(doc['tokens'], doc['ner_tags']):\n",
        "        rows.append({\"token\": token, \"ner_tag\": label})\n",
        "\n",
        "train_df = pd.DataFrame(rows)\n",
        "\n",
        "# Dataset statistics\n",
        "num_tokens = len(train_df)\n",
        "entity_counts = Counter(train_df['ner_tag'])\n",
        "print(f\"Number of tokens: {num_tokens}\")\n",
        "print(f\"Entity distribution (by label index): {entity_counts}\")\n",
        "\n",
        "# Log stats to W&B\n",
        "wandb.summary[\"num_tokens\"] = num_tokens\n",
        "wandb.summary[\"entity_distribution\"] = {str(k): v for k, v in entity_counts.items()}\n",
        "\n",
        "# ===============================\n",
        "# Step 2: Define Snorkel Labeling Functions\n",
        "# ===============================\n",
        "\n",
        "# Label constants\n",
        "PER, LOC, ORG, MISC, ABSTAIN = 0, 1, 2, 3, -1\n",
        "\n",
        "# LF1: Detect years 1900-2099 as MISC\n",
        "@labeling_function()\n",
        "def lf_years(x):\n",
        "    if re.fullmatch(r\"19\\d\\d|20\\d\\d\", x[\"token\"]):\n",
        "        return MISC\n",
        "    return ABSTAIN\n",
        "\n",
        "# LF2: Detect organizations by suffix\n",
        "org_suffixes = [\"Inc.\", \"Corp.\", \"Ltd.\", \"LLC\", \"Co.\"]\n",
        "\n",
        "@labeling_function()\n",
        "def lf_org_suffix(x):\n",
        "    if any(x[\"token\"].endswith(suffix) for suffix in org_suffixes):\n",
        "        return ORG\n",
        "    return ABSTAIN\n",
        "\n",
        "# ===============================\n",
        "# Step 2b: Apply LFs\n",
        "# ===============================\n",
        "\n",
        "lfs = [lf_years, lf_org_suffix]\n",
        "applier = LFApplier(lfs=lfs)\n",
        "\n",
        "# Convert DataFrame to list of dicts so each row is a dict\n",
        "train_records = train_df.to_dict(orient=\"records\")\n",
        "\n",
        "# Apply LFs\n",
        "L_train = applier.apply(train_records)\n",
        "\n",
        "# LF Analysis\n",
        "lf_summary_df = LFAnalysis(L=L_train, lfs=lfs).lf_summary()\n",
        "print(lf_summary_df)\n",
        "\n",
        "# ===============================\n",
        "# Step 2c: Log LF coverage & empirical accuracy to W&B safely\n",
        "# ===============================\n",
        "for i, lf in enumerate(lfs):\n",
        "    summary = lf_summary_df.iloc[i]\n",
        "\n",
        "    # Safe handling of coverage column\n",
        "    coverage_value = summary.get(\"coverage\") or summary.get(\"coverage_pct\") or None\n",
        "    accuracy_value = summary.get(\"empirical_accuracy\", None)\n",
        "\n",
        "    log_dict = {}\n",
        "    if coverage_value is not None:\n",
        "        log_dict[f\"{lf.name}_coverage\"] = coverage_value\n",
        "    if accuracy_value is not None:\n",
        "        log_dict[f\"{lf.name}_empirical_accuracy\"] = accuracy_value\n",
        "\n",
        "    wandb.log(log_dict)\n",
        "\n",
        "# ===============================\n",
        "# Step 3: Label Aggregation (Majority Voter)\n",
        "# ===============================\n",
        "# Specify cardinality=4 to handle 4 entity classes\n",
        "voter = MajorityLabelVoter(cardinality=4)\n",
        "y_train = voter.predict(L=L_train)\n",
        "\n",
        "# Compare with true labels\n",
        "true_labels = train_df[\"ner_tag\"].values\n",
        "accuracy = np.mean(y_train == true_labels)\n",
        "print(f\"Majority Label Voter accuracy: {accuracy:.4f}\")\n",
        "wandb.log({\"majority_voter_accuracy\": accuracy})\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "clo1TxmXe-5x",
        "outputId": "3b05a7bf-7421-4f7c-e298-04026453e489"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing previous runs because reinit is set to 'default'."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>num_tokens</td><td>203621</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">tough-star-13</strong> at: <a href='https://wandb.ai/142402014-indian-institute-of-technology/Q1-weak-supervision-ner/runs/67ke3kso' target=\"_blank\">https://wandb.ai/142402014-indian-institute-of-technology/Q1-weak-supervision-ner/runs/67ke3kso</a><br> View project at: <a href='https://wandb.ai/142402014-indian-institute-of-technology/Q1-weak-supervision-ner' target=\"_blank\">https://wandb.ai/142402014-indian-institute-of-technology/Q1-weak-supervision-ner</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20251013_170514-67ke3kso/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.22.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251013_170629-ed9dqdb9</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/142402014-indian-institute-of-technology/Q1-weak-supervision-ner/runs/ed9dqdb9' target=\"_blank\">royal-darkness-14</a></strong> to <a href='https://wandb.ai/142402014-indian-institute-of-technology/Q1-weak-supervision-ner' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/142402014-indian-institute-of-technology/Q1-weak-supervision-ner' target=\"_blank\">https://wandb.ai/142402014-indian-institute-of-technology/Q1-weak-supervision-ner</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/142402014-indian-institute-of-technology/Q1-weak-supervision-ner/runs/ed9dqdb9' target=\"_blank\">https://wandb.ai/142402014-indian-institute-of-technology/Q1-weak-supervision-ner/runs/ed9dqdb9</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of tokens: 203621\n",
            "Entity distribution (by label index): Counter({0: 169578, 5: 7140, 1: 6600, 3: 6321, 2: 4528, 4: 3704, 7: 3438, 6: 1157, 8: 1155})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "203621it [00:00, 224711.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               j Polarity  Coverage  Overlaps  Conflicts\n",
            "lf_years       0      [3]  0.002667       0.0        0.0\n",
            "lf_org_suffix  1      [2]  0.000108       0.0        0.0\n",
            "Majority Label Voter accuracy: 0.0000\n",
            "Assignment 5 script completed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t9fN80Sme-zh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}